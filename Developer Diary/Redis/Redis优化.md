## 一、数据同步与处理

* 业务来源：

  * 某数据业务存储在以日为单位的`日志表`中，存储了用户的uuid，但是未标记该用户的新用户属性。
  * 也就是说，`日志表`中无法知道用户是否是新用户。需要从另外一张`用户表`中读取用户的新用户属性，并添加到该记录中。
  * 最终的数据存储可以是多样的，可以是数据库或者其他分布式存储。

* 讨论点：
  * 简单的业务逻辑就是从数据库中读取该用户的属性，并把记录写入到日志记录中。但是单纯的数据库读取与写入是不可靠的，一个很大的原因就是性能。
  * 每一条日志记录读取到都要进行数据处理，日志可能进行一个很大的`日志表`和`用户表`都是一个量很大的表，无法承担高并发与高性能的查询。
  
* 实现方案：
  
  * 方案一：直接从数据库读取，处理并写入目标数据源也是一种方案。
  
    * 通过一个定时调度去实现每批次的数据处理
  
  * 方案二：功能拆分，进行一定程度的拆分，拆分成`同步`与`处理`
  
    * 其实这个就是一个ETL的功能实现。
  
    * 选用DataX作为同步工具，进行数据同步，并把数据写入到Kafka
  
    * 通过Flink任务实时处理数据并写入到目标数据源。
  
  |        | 优点         | 缺点                                                         | 开发                                       |
  | ------ | ------------ | ------------------------------------------------------------ | ------------------------------------------ |
  | 方案一 | **开发迅速** | **扩展性差**：这样的处理在业务上处理比较麻烦。 <br />**单节点性能问题**：会有单节点的性能问题。<br /> **复用性差**：改问题解决了，后续的类似问题还需要开发处理。 | 单个任务开发                               |
  | 方案二 | **业务拆分** | **复用**：部分功能可结合其他任务使用<br /><br />**Flink高性能**：结合kafka后，Flink可实现更好的处理 | DataX调度开发<br />Flink任务调度开发<br /> |
  
* 重点克服问题：

  * 面对如此量的`日志表`和`用户表`。日志表的数据处理已经通过了Kafka与Flink实现，大可不必担心其性能。但是`用户表`的性能如何提升？第一想到的就是Redis实现。
  * 通过一个把用户uuid值，写入到redis中。一条日志信息处理，只需要把判断redis中有没有该用户信息，有的话就是新用户，没有就是老用户了。
    * 这里可以直接使用Python实现，因为任务是要每天调度更新的。Python开发也提供了很大的便捷性。第一次先通过一次性把历史的用户信息全部加载到redis。以后以日为单位，每次只需要更新昨日数据，更新加载到Redis即可。
    * 方案一（Hash处理）：
      * redis存储结构为Hash，所有信息存入一个Hash的Key中，每个用户的信息以{uuid:第一次活跃时间}作为键值对存储。因为有kafka有部分数据（数据库以日表统计，每日会有额外的一个同步任务）会延迟加载，所以value上加了第一次活跃时间用于二次判断。
      * 该方案理论是可行的，但是实际实现效果并不佳，耗费了大量的内存，这个内存的消耗量是目前服务器所不能接受的。
        * **100W数据在key和value都在10Byte左右时，占用空间100M左右**。
        * 目前配置7000W数据，消耗内存大概在7个G的大小，但实际单位是在亿级别上的，这样子只能靠扩大内存来处理，或者寻求新的存储方案。
    * 方案二（Hash处理）：
      * 利用Redis的setbit特性，建立一个以用户id作为map的统一管理，就在bitmap中把标识此用户的位置为1。实际上，我们采用的是uuid为数据id，那么就要把uuid转成对应的编码。
      * Redis的 setbit(key, offset, value)操作对指定的key的value的指定偏移(offset)的位置1或0，时间复杂度是O(1)。
      * Redis的存储长度为512M：对应的就是2^32次方。uuid为32位。一个字母2^4，那么剩下只能存储8个字母。就需要把uuid拆分成4段，每段大小转码成为二进制编码刚好符合2^32，用4段分别存储。
      * 实际测试后，单线程操作，1W条数据，4W次setbit，时间约为3s。300W
      * 存在的两个问题：
        * 会不会存在问题，很简单的逻辑，AB、CD拆分，AD、CB也会出现？
        * 没有了时间单位，如果处理redis刷新了`用户表`，但是`日志表`延迟了。也就是说，第二天Redis把昨日的`用户表`刷新了，但是实际上`日志表`中新用户也延迟读取进来，这个时候，该新用户加载了新的redis，被识别位老用户了？
      * 误差的接受能力：
        * 第一个问题：
          * 
        * 第二个问题：
          * 实际的业务能力上可以处理在10分钟之内的数据误差。
